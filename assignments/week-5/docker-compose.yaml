#Direct the main healthcheck to port 8000
#Direct the face-bokeh to port 8001
#Direct the face-emotion to port 8002
version: '3.7'

services:

  face-bokeh:
    build: ./face-bokeh
    container_name: face-bokeh-cntnr
    image: face-bokeh-img
    ports: 
          - 8003:8000

  face-emotion:
    build: ./face-emotion
    container_name: face-emotion-cntnr
    image: face-emotion-img
    ports: 
          - 8002:8000
  
  main_service:
      build: .
      container_name: two-face-cntnr
      image: two-face-img
      ports:
          - 8001:8000
      depends_on:
          - inference_server

  inference_server:
    container_name: triton
    env_file:
        .aws.env
    ports:
      - 8000:8000
    image: nvcr.io/nvidia/tritonserver:22.06-py3
    #network_mode: host
    command:
        ['tritonserver', '--model-repository=s3://shobha-mur-week1/models/']


# version: '3.7'
# face-bokeh:
#     build: ./face-bokeh
#     container_name: face-bokeh-cntnr
#     image: face-bokeh-img
#     ports: 
#           - 8001:8002

#   face-emotion:
#     build: ./face-emotion
#     container_name: face-emotion-cntnr
#     image: face-emotion-img
#     ports: 
#           - 8003:8002
# services:

#   main_service:
#     build: .
#     container_name: two-face-cntnr
#     image: two-face-img
#     ports:
#         - 8003:8000
#     depends_on:
#         - inference_server

#   inference_server:
#     container_name: triton
#     env_file:
#         .aws.env
#     ports:
#       - 8000:8000
#       - 8001:8001
#       - 8002:8002
#       - 8003:8003
#     image: nvcr.io/nvidia/tritonserver:22.06-py3
#     network_mode: host
#     command:
#       ['tritonserver', '--model-repository=s3://shobha-mur-week1/models/']
